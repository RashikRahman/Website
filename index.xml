<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rashik Rahman on Home</title>
    <link>https://rashikrahman.github.io/Website/</link>
    <description>Recent content in Rashik Rahman on Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Apr 2021 10:58:08 -0400</lastBuildDate>
    
	<atom:link href="https://rashikrahman.github.io/Website/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Project 18: Pneumonia classification from covid patient chest xray</title>
      <link>https://rashikrahman.github.io/Website/post/project-18/</link>
      <pubDate>Thu, 15 Apr 2021 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-18/</guid>
      <description>Developed a CNN model to recognize pneumonia from chest xray of covid patients. Also the model is implemented in web-end for ease of use. Dependencies to run the web-edn are the followings:
Flask==1.1.2 joblib==1.0.1 Keras==2.4.3 numpy scipy==1.5.4 opencv-python==4.5.1.48 pywebio==1.2.3 scikit-image tensorflow==2.4.1 argparse How to use? Clone the repo(link attached below), then goto the server subdirectory. Open anaconda dir and type in the following commands.
cd &amp;#39;path_to_repo/Server&amp;#39; pip install -r requirements.txt After installation of the dependencies now you need to run the following command.</description>
    </item>
    
    <item>
      <title>Project 17: Market Basket Analysis</title>
      <link>https://rashikrahman.github.io/Website/post/project-17/</link>
      <pubDate>Sat, 20 Mar 2021 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-17/</guid>
      <description>What&amp;rsquo;s Market Basket Analysis(MBA) Market basket analysis is one of the key techniques used by retailers to increase sales by better understanding customer purchasing patterns. It involves analyzing large data sets, such as purchase history, to reveal product groupings, as well as products that are likely to be purchased together. It works by looking for combinations of items that occur together frequently in transactions. Association Rules are widely used to analyze retail basket or transaction data, and are intended to identify strong rules discovered in transaction data using measures of interestingness, based on the concept of strong rules.</description>
    </item>
    
    <item>
      <title>Project 16: Plant Pathology Recognition with PyWebIO</title>
      <link>https://rashikrahman.github.io/Website/post/project-16/</link>
      <pubDate>Wed, 17 Mar 2021 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-16/</guid>
      <description>This is a plant disease recognition project. I used a CNN to build the deep learning model for recognition and used PyWebIO &amp;amp; flask for a web end interface. Model accuracy is over 91% in classification report. Due to bandwidth issue couldn&amp;rsquo;t upload the model.h5 file but hope to update it soon.
You need to locate to the directory where you clone this repo. You can use command promt or anaconda powershell.</description>
    </item>
    
    <item>
      <title>Project 15: Sentiment Classification with PyTorch &amp; FastApi</title>
      <link>https://rashikrahman.github.io/Website/post/project-15/</link>
      <pubDate>Wed, 10 Feb 2021 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-15/</guid>
      <description>This is a binary text classification project. I used pytorch to create the model with help of tez wrapper. Then used FastApi to deploy the model. The model.bin file couldn&amp;rsquo;t be uploaded due to it&amp;rsquo;s huge file, but you can run the project and create your own model.
There are two ways to run this model. Either you can train the model on colab or train it locally. If you want to run it in colab then just copy past the whole code written in NLP_Model.</description>
    </item>
    
    <item>
      <title>Project 14: Image Video Colorization</title>
      <link>https://rashikrahman.github.io/Website/post/project-14/</link>
      <pubDate>Fri, 15 Jan 2021 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-14/</guid>
      <description>Hey there this is Rashik Rahman. This is a fun project to prectice openCV. The model files are open source and very available to use. I just took the pre-trained models and implemented those with openCV. To run this project you need to do the followings.
You need to locate to the directory where you clone this repo. You can use command promt or anaconda powershell. To locate to repo you just need to type in this command.</description>
    </item>
    
    <item>
      <title>Project 13:Facial Recognition Attendance System</title>
      <link>https://rashikrahman.github.io/Website/post/project-13/</link>
      <pubDate>Tue, 05 Jan 2021 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-13/</guid>
      <description>This is an automation of face recognition attendance system. This project is with out gui so there&amp;rsquo;s a loop whole in taking the attendance that I intentionally didn&amp;rsquo;t resolve as I&amp;rsquo;ll develop a gui interface on it in near future. You may resolve that loop whole with a simple logic of &amp;lsquo;if preson name &amp;amp; current date exists in csv then don&amp;rsquo;t save else save&amp;rsquo;.
How to run? At first you&amp;rsquo;ll need to install Visual Studio c++ compiler.</description>
    </item>
    
    <item>
      <title>Project 12: Text Tagging</title>
      <link>https://rashikrahman.github.io/Website/post/project-12/</link>
      <pubDate>Tue, 27 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-12/</guid>
      <description>About dataset : To develop this project I used fetch_20newsgroups which is sklearn&amp;rsquo;s open source dataset. Following are the labels in the dataset.
 Data preparation was done thoroughly using TfidfVectorizer. Used MultiNomial Gaussian Naive Bayes algorithm to develop this project. Model accuracy is 77% The developed model will show the type of given input text.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 11: Spam Classifier</title>
      <link>https://rashikrahman.github.io/Website/post/project-11/</link>
      <pubDate>Sat, 24 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-11/</guid>
      <description>About dataset : Open source dataset containing 5773 text messages of spam and ham was used to develop this project.
Correlation between the attributes
 Data preparation was done thoroughly using CountVectorizer. Used MultiNomial Gaussian Naive Bayes algorithm to develop this project. Model accuracy is 98%  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 10: Maleware Detection</title>
      <link>https://rashikrahman.github.io/Website/post/project-10/</link>
      <pubDate>Fri, 16 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-10/</guid>
      <description>About dataset : These are the column of the dataset representing various aspects of a software. These will decide if a software is legit or malware
Correlation between the attributes
 Data preparation was not that much needed cause it was already a well proccesed data. Did Hyper parameter tunning using GridSearchCV Among GaussianNB, AdaBoostClassifier, DecisionTreeClassifier, KNeighborsClassifier, SVM, RandomForest, LogisticRegression, RandomForest performed best with score of 99.1%  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 9: Heart Attack Detection</title>
      <link>https://rashikrahman.github.io/Website/post/project-9/</link>
      <pubDate>Sat, 10 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-9/</guid>
      <description>About dataset :   Age : Age of the patient
  Sex : Sex of the patient
  exang: exercise induced angina (1 = yes; 0 = no)
  ca: number of major vessels (0-3)
  cp : Chest Pain type chest pain type
 Value 1: typical angina Value 2: atypical angina Value 3: non-anginal pain Value 4: asymptomatic    trestbps : resting blood pressure (in mm Hg)</description>
    </item>
    
    <item>
      <title>Project 8: Sales Insights Using PowerBI</title>
      <link>https://rashikrahman.github.io/Website/post/project-8/</link>
      <pubDate>Tue, 07 Jul 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-8/</guid>
      <description>Tools used : PowerBI, MySql Here the problem was a XYZ company was suffering from sales decline. So they wanted to see the insights of their sales and would take necessary decision based on that like closing a dealership etc. So my task was to design a dynamic intuitive dashboard from their database so that they can easily understand about their sales insights.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 7: An Analysis of Data Science Job</title>
      <link>https://rashikrahman.github.io/Website/post/project-7/</link>
      <pubDate>Wed, 24 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-7/</guid>
      <description>Code and Resources Used   Packages: pandas, numpy, sklearn, matplotlib, seaborn, selenium
  Scraper Github: https://github.com/arapfaik/scraping-glassdoor-selenium
  Scraper Article: https://towardsdatascience.com/selenium-tutorial-scraping-glassdoor-com-in-10-minutes-3d0915c6d905
  Web Scraping  Tweaked the web scraper github repo (above) to scrape 1000 job postings from glassdoor.com. With each job, we got the following: Job title Salary Estimate Job Description Rating Company Location Company Headquarters Company Size Company Founded Date Type of Ownership Industry Sector Revenue Competitors  Data Cleaning   After scraping the data, I needed to clean it up so that it was usable for our model.</description>
    </item>
    
    <item>
      <title>Project 6: Face Matching Classifier</title>
      <link>https://rashikrahman.github.io/Website/post/project-6/</link>
      <pubDate>Tue, 23 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-6/</guid>
      <description>The data was scraped from pinterest using FetKun. Data was prepared using opencv and visualized using matplotlib. Data preparation was done thoroughly. Did Hyper parameter tunning using GridSearchCV Among SVM, LogisticRegression, RandomForest, LogisticRegression performed best with score of 78%  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 5: Bollywood Movie Recommendation Engine</title>
      <link>https://rashikrahman.github.io/Website/post/project-5/</link>
      <pubDate>Sun, 07 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-5/</guid>
      <description>The data was scraped from wikipedia using beautifulsoup. Data was prepared using pandas and visualized using matplotlib. Analysis and data preparation was done thoroughly.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 4: HR Analytics &amp; Modeling</title>
      <link>https://rashikrahman.github.io/Website/post/project-4/</link>
      <pubDate>Sat, 06 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-4/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib &amp;amp; seaborn. Analysis was done thoroughly. Tried KNN, DecisionTree, LogisticRegression. And DecisionTree classifier algorithm was choosen with accuracy of 97%.  Link to Notebook</description>
    </item>
    
    <item>
      <title>Project 3: Salary Classifier</title>
      <link>https://rashikrahman.github.io/Website/post/project-3/</link>
      <pubDate>Mon, 01 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-3/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib. Analysis was done thoroughly. Tried KNN, SVM, DecisionTree, LogisticRegression, RandomForest, AdaBoost, GaussianNB Algorithm. And AdaBoost classifier algorithm was choosen with accuracy of 81%.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 2: Car Price Prediction</title>
      <link>https://rashikrahman.github.io/Website/post/project-2/</link>
      <pubDate>Fri, 29 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-2/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib. Prediction was done using LinearRegression, model accuracy 84%. Web frame used was django.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 1: Bangalore price prediction</title>
      <link>https://rashikrahman.github.io/Website/post/project-1/</link>
      <pubDate>Fri, 24 Apr 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-1/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib. Prediction was done using LinearRegression, model accuracy 89%. Web frame used was flask. Locally hosted using Nginx.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Certifications</title>
      <link>https://rashikrahman.github.io/Website/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/certification/</guid>
      <description>Conferences GGCS Paper
BDonor Paper
AI Poet Paper
Talks A To Z Tricks of Data Science &amp;amp; Machine Learning
Workshop on a Beginner&amp;rsquo;s Guide to start ML, Projects, Ckacking ML Production Pipeline
Course Certification IBM DATA SCIENCE Professional Certification
DeepLearning.AI TensorFlow Developer
Applied Data Science with Python
Machine Learning by Stanford University
Advanced Machine Learning with TensorFlow on Google Cloud Platform Specialization</description>
    </item>
    
  </channel>
</rss>