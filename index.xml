<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rashik Rahman on Home</title>
    <link>https://rashikrahman.github.io/Website/</link>
    <description>Recent content in Rashik Rahman on Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Oct 2020 10:58:08 -0400</lastBuildDate>
    
	<atom:link href="https://rashikrahman.github.io/Website/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Project 12: Text Tagging</title>
      <link>https://rashikrahman.github.io/Website/post/project-12/</link>
      <pubDate>Tue, 27 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-12/</guid>
      <description>About dataset : To develop this project I used fetch_20newsgroups which is sklearn&amp;rsquo;s open source dataset. Following are the labels in the dataset.
 Data preparation was done thoroughly using TfidfVectorizer. Used MultiNomial Gaussian Naive Bayes algorithm to develop this project. Model accuracy is 77% The developed model will show the type of given input text.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 11: Spam Classifier</title>
      <link>https://rashikrahman.github.io/Website/post/project-11/</link>
      <pubDate>Sat, 24 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-11/</guid>
      <description>About dataset : Open source dataset containing 5773 text messages of spam and ham was used to develop this project.
Correlation between the attributes
 Data preparation was done thoroughly using CountVectorizer. Used MultiNomial Gaussian Naive Bayes algorithm to develop this project. Model accuracy is 98%  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 10: Maleware Detection</title>
      <link>https://rashikrahman.github.io/Website/post/project-10/</link>
      <pubDate>Fri, 16 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-10/</guid>
      <description>About dataset : These are the column of the dataset representing various aspects of a software. These will decide if a software is legit or malware
Correlation between the attributes
 Data preparation was not that much needed cause it was already a well proccesed data. Did Hyper parameter tunning using GridSearchCV Among GaussianNB, AdaBoostClassifier, DecisionTreeClassifier, KNeighborsClassifier, SVM, RandomForest, LogisticRegression, RandomForest performed best with score of 99.1%  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 9: Heart Attack Detection</title>
      <link>https://rashikrahman.github.io/Website/post/project-9/</link>
      <pubDate>Sat, 10 Oct 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-9/</guid>
      <description>About dataset :   Age : Age of the patient
  Sex : Sex of the patient
  exang: exercise induced angina (1 = yes; 0 = no)
  ca: number of major vessels (0-3)
  cp : Chest Pain type chest pain type
 Value 1: typical angina Value 2: atypical angina Value 3: non-anginal pain Value 4: asymptomatic    trestbps : resting blood pressure (in mm Hg)</description>
    </item>
    
    <item>
      <title>Project 8: Sales Insights Using PowerBI</title>
      <link>https://rashikrahman.github.io/Website/post/project-8/</link>
      <pubDate>Tue, 07 Jul 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-8/</guid>
      <description>Tools used : PowerBI, MySql Here the problem was a XYZ company was suffering from sales decline. So they wanted to see the insights of their sales and would take necessary decision based on that like closing a dealership etc. So my task was to design a dynamic intuitive dashboard from their database so that they can easily understand about their sales insights.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 7: An Analysis of Data Science Job</title>
      <link>https://rashikrahman.github.io/Website/post/project-7/</link>
      <pubDate>Wed, 24 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-7/</guid>
      <description>Code and Resources Used   Packages: pandas, numpy, sklearn, matplotlib, seaborn, selenium
  Scraper Github: https://github.com/arapfaik/scraping-glassdoor-selenium
  Scraper Article: https://towardsdatascience.com/selenium-tutorial-scraping-glassdoor-com-in-10-minutes-3d0915c6d905
  Web Scraping  Tweaked the web scraper github repo (above) to scrape 1000 job postings from glassdoor.com. With each job, we got the following: Job title Salary Estimate Job Description Rating Company Location Company Headquarters Company Size Company Founded Date Type of Ownership Industry Sector Revenue Competitors  Data Cleaning   After scraping the data, I needed to clean it up so that it was usable for our model.</description>
    </item>
    
    <item>
      <title>Project 6: Face Matching Classifier</title>
      <link>https://rashikrahman.github.io/Website/post/project-6/</link>
      <pubDate>Tue, 23 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-6/</guid>
      <description>The data was scraped from pinterest using FetKun. Data was prepared using opencv and visualized using matplotlib. Data preparation was done thoroughly. Did Hyper parameter tunning using GridSearchCV Among SVM, LogisticRegression, RandomForest, LogisticRegression performed best with score of 78%  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 5: Bollywood Movie Recommendation Engine</title>
      <link>https://rashikrahman.github.io/Website/post/project-5/</link>
      <pubDate>Sun, 07 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-5/</guid>
      <description>The data was scraped from wikipedia using beautifulsoup. Data was prepared using pandas and visualized using matplotlib. Analysis and data preparation was done thoroughly.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 4: HR Analytics &amp; Modeling</title>
      <link>https://rashikrahman.github.io/Website/post/project-4/</link>
      <pubDate>Sat, 06 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-4/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib &amp;amp; seaborn. Analysis was done thoroughly. Tried KNN, DecisionTree, LogisticRegression. And DecisionTree classifier algorithm was choosen with accuracy of 97%.  Link to Notebook</description>
    </item>
    
    <item>
      <title>Project 3: Salary Classifier</title>
      <link>https://rashikrahman.github.io/Website/post/project-3/</link>
      <pubDate>Mon, 01 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-3/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib. Analysis was done thoroughly. Tried KNN, SVM, DecisionTree, LogisticRegression, RandomForest, AdaBoost, GaussianNB Algorithm. And AdaBoost classifier algorithm was choosen with accuracy of 81%.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 2: Car Price Prediction</title>
      <link>https://rashikrahman.github.io/Website/post/project-2/</link>
      <pubDate>Fri, 29 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-2/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib. Prediction was done using LinearRegression, model accuracy 84%. Web frame used was django.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Project 1: Bangalore price prediction</title>
      <link>https://rashikrahman.github.io/Website/post/project-1/</link>
      <pubDate>Fri, 24 Apr 2020 10:58:08 -0400</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/post/project-1/</guid>
      <description>The data was collected from kaggle. Data was prepared using pandas and visualized using matplotlib. Prediction was done using LinearRegression, model accuracy 89%. Web frame used was flask. Locally hosted using Nginx.  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Certifications</title>
      <link>https://rashikrahman.github.io/Website/certification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rashikrahman.github.io/Website/certification/</guid>
      <description>These are the current certifications I have till now.
Python Programmer
IBM DATA SCIENCE Professional Certification
IBM Applied Data Science Specialist Certification
Machine Learning by Stanford University
Machine Learning with TensorFlow on Google Cloud Platform
Advanced Machine Learning with TensorFlow on Google Cloud Platform Specialization
Data Scientist with Python
Machine Learning Scientist with Python
Data Science Math Skills
Advanced Data Science with IBM
Applied Data Science with Python
Data Analyst with Python</description>
    </item>
    
  </channel>
</rss>